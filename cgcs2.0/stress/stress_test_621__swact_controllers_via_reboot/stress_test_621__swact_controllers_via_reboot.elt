#!/usr/bin/env expect-lite

# How to use this expect-lite file, Lines that begin with:
#	'>' send to remote host, implies "wait for prompt"
#	'<' _MUST_ be received from the remote host, or this config script will fail
#	# are comment lines, and have no effect
#	; are printable (in stdout) comments, and have no other effect
#	@ change the expect timeout value
#	! Embedded Expect commands
# For more info see: expect-lite.html

#*~fail.inc
#
#	
#	
#
#
;;;

Test 621 Stress controller swact via reboot

Based on:
        Stress: Run 15 Controller swacts triggered by reboot -f command

        1. use crm status command to check that all resources are running on
        the active controller
        2. From NAT box monitor pings to VMs management ip
        3. Choose 2 VMs per compute node and from the NAT box set up
        an ssh session per VM (login as root/root) and run the script
        which will write to the rootfs filesystem every second
        4. On the active controller, issues reboot -f command to reboot
        controller.
        5. After controller reboot is complete, wait 5 minutes.
        6. Ensure no ping loss to any VM
        7. Ensure all VMs stay in ACTIVE/Running state
        8. Ensure inactive controller (the controller that is not rebooted)
        takes activity and all resources are running on the newly active
        controller within 60 seconds. (Monitor via crm status command)
        9. Ensure that all resources stay on the newly active Controller
        (ie: the controller that is not rebooted) and no swact back occurs
         within next 5 minutes before repeat TC.
        10. Ensure all filesystems in Guest remain R/W - use mount command
        11. Ensure the script continues to run in each of the VMs
        12. Repeat the sequence.




Assumptions:
	Lab is setup with lab_setup.sh with Tenants
	Flavors small & medium.dpdk are already provisioned
	
Limitations:
	Test must be run in real lab with natbox access - vbox not supported

;;;

Steps:
1)  Connect to controller
2)  Become admin
3)  Show version
4)  Check for tenant credentials
5)  Display configuration
6)  Look at neutron config
7)  Show volumes in cinder
8) = show images in glance
9)  Create big flavor
10)  Get tenant uuids
11)  Look at quotas for $tenant
12)  Increase quotas for test
13)  Determine number of computes online
14)  Switch to tenant mode
15)  Get volumes
16)  Show volumes in cinder
17)  Check for running VMs
18)  Boot VMs
19)  Wait for VM to boot up
20)  Check VMs are not in ERROR state
21)  Get VM mananagement IP
22)  Ping VM
23)  Connect to VM
24)  Inside VM, check filesystem and ping
25)  Start stress loop
26)  Stress loop count: $count
27)  Become admin
28)  Set up sudo root access (to make it easier later in the interact session)
29)  Wait for second controller to be available
30)  Identify active controller
31)  Set up sudo root access (to make it easier later in the interact session)
32)  Fail active controller
33)  Wait for swact
34)  Check that horizon is up
35)  Log into new active controller
36)  Become admin
37)  Identify active controller
38)  Check VM is still writing to FS
39)  Stress done
40)  Cleanup
41)  Switch to tenant mode
42)  Become Admin to delete flavor
43)  Reset quotas for $tenant


*NOFAIL
*EXP_INFO

$IP=10.10.10.2

# support custom port support
?if $PORT != $blank ? $ssh_opts= -p $PORT :: $ssh_opts= -o UserKnownHostsFIle=/dev/null -o StrictHostKeyChecking=no 

$user=wrsroot
$pass=li69nux

$tenant_credentials=/home/wrsroot/openrc.tenant1
$tenant=$tenant_credentials
# trim to just last part
=$tenant;.*[.](\w+);\1;

# expand quotas for scaling test
$quota_instances=30
$quota_vcpus=60
$quota_port=60

# flavors used by VM1 and VM2
$flavor2=small
$flavor1=medium.dpdk
$flavor1=big

# second flavor and number of vcpus
$flavor3=big
$flavor3_vcpu=1

$best_effort=true
$best_effort=false

$max_vms=2

# number of times to stress
$max_stress=15
#$max_stress=2

# VM names
$guest1=VM1
$guest2=VM2

# image name
$image_name=cgcs-guest
$image_name=wrl5


# wait for "other" compute to be up before proceeding in stress loop
$wait_for_second_compute=yes
$max=50
# minimum number of computes available when evacuating
$min_controllers=2

#vm file system test
$vm_fs_test=while (true) do date; dd if=/dev/urandom of=output.txt bs=1k count=1 conv=fsync || break ; echo ; sleep 1; done 2>&1 | tee trace.txt

$natbox_addr=128.224.150.11
$natbox_user=cgcs
$natbox_pass=li69nux



*FORK default

; === connect to controller


>ssh -X $ssh_opts -o UserKnownHostsFIle=/dev/null -o StrictHostKeyChecking=no $user@$IP
-<WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED
<ssword:|WARNING:
>>$pass
<SYSTEM:|WARNING:
+$system_type=(vbox|yow-cgcs-ironpass-\d+|yow-cgcs-hp380-\d+)

?if $system_type == vbox ? [
	;red This test case requires NAT Box
	*TERM 5
]
?if $system_type == __NO_STRING_CAPTURED__ ? $system_type=vbox


>export TMOUT=0

; === become admin

>source /etc/nova/openrc 



; === show version

>system show
>cat /etc/build.info


; === check for tenant credentials
>stat -t $tenant_credentials
+$file_stat=\n.*($tenant_credentials|No such file)

?if $file_stat != $tenant_credentials? [
		;red Tenant Credentials file:$tenant_credentials missing, skipping
		*TERM 5
]


---------------- start test ---------------------

>system host-list


; === display configuration

; === look at neutron config
# prep for getting to VM
>neutron net-list
+$internal_net_uuid=([0-9a-f-]{36}) \| internal0
+$tenant1_net_uuid=([0-9a-f-]{36}) \| tenant1-net0
+$tenant1_mgmt_net_uuid=([0-9a-f-]{36}) \| tenant1-mgmt-net

>neutron dhcp-agent-list-hosting-net $tenant1_mgmt_net_uuid
+$vm_netns_host=(compute-\d+)

>neutron subnet-list
>neutron router-list


; === show volumes in cinder
>cinder list --all-tenants 
>cinder list --all-tenants  |grep $tenant
+$cinder_volume=([0-9a-f-]{36})

?if $cinder_volume == __NO_STRING_CAPTURED__? [
	;red No cinder volume found
	*FAIL
	?if true == true? %CLEANUP
]



; === create big flavor 
@5
>nova flavor-create $flavor3 5f0d748b-1c8b-4a70-8643-4d57e25ac137 512 1 $flavor3_vcpu
#>nova flavor-key 5f0d748b-1c8b-4a70-8643-4d57e25ac137 unset guest:heartbeat=False
>nova flavor-key 5f0d748b-1c8b-4a70-8643-4d57e25ac137 set guest:heartbeat=True
>nova flavor-list --extra-spec


>nova flavor-list
<VCPU_Model
+$flavor1_uuid=([0-9a-f-]{36}|\d{3})\s* \| $flavor1 
+$flavor2_uuid=([0-9a-f-]{36}|\d{3})\s* \| $flavor2 

; === get tenant uuids
>keystone tenant-list
<name
+$tenant_uuid=([0-9a-f-]{32}|\d{3})\s* \| $tenant 

; === Look at quotas for $tenant
>nova quota-show --tenant $tenant_uuid
<instances
+$tenant_quota_instances=(\d+)
<cores
+$tenant_quota_vcpus=(\d+)

>neutron quota-show --tenant-id $tenant_uuid
<port
+$tenant_quota_port=(\d+)

?if $system_type != vbox ? [
	; === increase quotas for test
	>nova quota-update --instances $quota_instances $tenant_uuid
	>nova quota-update --cores $quota_vcpus $tenant_uuid
	# must use tenant uuid when updating neutron quotas
	>neutron quota-update --port $quota_port --tenant-id $tenant_uuid
]

; === Determine number of computes online
>system host-list | grep compute | grep available
>system host-list | grep compute | grep available | wc -l
+$num_of_computes=\n(\d+)

; === switch to tenant mode
>source $tenant_credentials

; === get volumes
>nova volume-list
+$volume_uuid=([0-9a-f-]{36}) \|


; === show volumes in cinder
>cinder list 
>cinder list  |grep virtio
+$cinder_volume_1=([0-9a-f-]{36})
<$cinder_volume_1
+$cinder_volume_2=([0-9a-f-]{36})



$i=1
; === check for running VMs
# use existing VM rather than starting one.
>nova list --all-tenants | grep tenant1
+$vm_uuid_$i=([0-9a-f-]{36}) \| 
#<$vm_uuid_$i
#+$i
#+$vm_uuid_$i=([0-9a-f-]{36}) \| 
#


#$max_vms=$num_of_computes

?if $vm_uuid_$i == __NO_STRING_CAPTURED__ ?[
	; === boot VMs
	@10
	$i=1
	[ $i <= $max_vms	
		# image boot
		#>nova boot --key_name=keypair-tenant1 --flavor=$flavor1_uuid --nic net-id=$tenant1_mgmt_net_uuid,vif-model=virtio --nic net-id=$tenant1_net_uuid,vif-model=virtio --image=$glance_image_name  $guest1-$i
		# cinder boot
		>nova boot --key_name=keypair-tenant1 --flavor=$flavor1_uuid --nic net-id=$tenant1_mgmt_net_uuid,vif-model=virtio --nic net-id=$tenant1_net_uuid,vif-model=virtio --block_device_mapping vda=$cinder_volume_$i:::0  $guest1-$i
		!sleep 3
		>nova list
		+$vm_uuid_$i=([0-9a-f-]{36}) \| $guest1-$i

		#+$vm_name=$guest1_$i
		$guest1_$i=$guest1-$i
		+$i
	]
	$use_existing_vm=no
]::[
	$use_existing_vm=yes
	>nova list
	+$guest1_$i=$vm_uuid_$i \| ([a-zA-Z0-9_-]+)

]
# only 1 VM for now
-$i
$max_vms=$i

; === wait for VM to boot up
@20
$i=0
$max=50
$vm_state=none
[ $vm_state != ACTIVE
	>nova list
	<$guest1_$max_vms
	+$vm_state=(BUILD|ACTIVE|ERROR)

	!sleep 5
	+$i
	?if $i > $max? %BREAK_VM_BOOT
	
	?if $vm_state == ERROR? %BREAK_VM_BOOT
]
%BREAK_VM_BOOT
@5
; === check VMs are not in ERROR state
>nova list
<Networks
-<ERROR

; === get VM mananagement IP
$i=1
[ $i <= $max_vms
	>nova list --all-tenants
	<$guest1_$i
	+$vm_ip$i=tenant1-mgmt-net=([0-9.]{7,15})
	+$i
]


---------- VM 1-------
*FORK vm1

>ssh $ssh_opts  $natbox_user@$natbox_addr
<ssword:|WARNING:
>>$natbox_pass



$k=1
; --- frontdoor to log into VM
@30


?if $system_type != vbox ? $ping_count=5 :: $ping_count=30
; === ping VM
@50
>ping -c $ping_count $vm_ip$k
<ttl=\d\d
>>^C

>ping -c 2 $vm_ip$k
+$ping_result=(\d+ received| 0 received)
@5
?if $ping_result != 0 received ? [
	; waiting for sshd service...
	#!sleep 5
	; === connect to VM
	*/.*: /
	$i=0
	$response=refused
	[ $response != ssword
		>ssh $ssh_opts root@$vm_ip$k
		+$response=(ssword|refused|Warning)
		!sleep 2
		+$i
		; --- retry $i
		?if $i > $max? [
			;red VM:$vm_ip sshd not responding
			*FAIL
			>exit
			>exit
			>
			# bail early
			?if true == true? %CLEANUP
		]
	]
	#<ssword:
	>>root
	; === inside VM, check filesystem and ping
	# clear prompt
	*//
	@5
	>root
	>
	>mount | grep root
	</ type \w+ \(rw
	>ip route
	<default via
	+$vm_default_gw=([0-9.]{7,15})
	>ping -c 2 $vm_default_gw
	<(2|1) received
	>$vm_fs_test
]



; === start stress loop
*FORK default 
$count=0
[ $count < $max_stress
	; === stress loop count: $count
	
	; === become admin
	>source /etc/nova/openrc 
	; === set up sudo root access (to make it easier later in the interact session)
	>echo "$pass" | sudo -S id
	<root
	
	; === wait for second controller to be available
	>system host-list | grep controller | grep available
	>system host-list | grep controller | grep available | wc -l
	$i=0
	+$num_of_controllers=\n(\d)
	[ $num_of_controllers < $min_controllers
		>system host-list | grep controller | grep available | wc -l
		+$num_of_controllers=\n(\d)
		!sleep 5
		+$i
		?if $i > $max ? %STOP_WAIT
	]
	%STOP_WAIT
	>system host-list 

	


	>system sda-list
	>
	; === identify active controller
	>system sda-list | grep controller-services
	+$act_controller=controller-services.*(controller-\d).*active

	; === set up sudo root access (to make it easier later in the interact session)
	>echo "$pass" | sudo -S id
	<root
	; === fail active controller	
	@3
	>
	>sudo reboot -f
	>
	# disconnect ssh session
	>>~.
	<Connection to .* closed
	>
	; === wait for swact
	@50
	>ping -c 35 -W 35 $IP
	<icmp_seq=\d+ ttl=\d\d
	<packets transmitted
	>
	; === check that horizon is up
	$return_code=1
	[ $return_code != 0
		>nc -w 2 $IP 80
		>echo $?
		+$return_code=\n(\d)
		!sleep 3
	]
	


	@5
	; === log into new active controller
	>ssh -X $ssh_opts $user@$IP
	<assword|SYSTEM:
	>>$pass
	>export TMOUT=0
	; === become admin

	>source /etc/nova/openrc 
	; === identify active controller
	>system sda-list | grep controller-services
	+$act_controller=controller-services.*(controller-\d).*active
	

	
	
	
	
	; === check VM is still writing to FS
	*FORK vm1
	!sleep 2
	>>
	<1024 bytes

	*FORK default
	>>

	+$count
]
# end of max_stress



; === stress done

*INTERACT

%CLEANUP
*FORK vm1
>>^C
>grep -i error trace.txt
>tail trace.txt
>date
>

*FORK default
; === cleanup 
@10
; === switch to tenant mode
>source $tenant_credentials

?if $use_existing_vm==no ? [
	$i=1
	[ $i <= $max_vms
		>nova delete $vm_uuid_$i
		+$i
	]
]

>
!sleep 1
>nova list

; === Become Admin to delete flavor
>source /etc/nova/openrc 
>nova flavor-delete $flavor3

?if $system_type != vbox ? [
	; === reset quotas for $tenant
	>nova quota-update --instances $tenant_quota_instances $tenant_uuid
	>nova quota-update --cores $tenant_quota_vcpus $tenant_uuid
	>neutron quota-update --port $tenant_quota_port --tenant-id $tenant_uuid
]
>


