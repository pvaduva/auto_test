#!/usr/bin/env expect-lite

# How to use this expect-lite file, Lines that begin with:
#	'>' send to remote host, implies "wait for prompt"
#	'<' _MUST_ be received from the remote host, or this config script will fail
#	# are comment lines, and have no effect
#	; are printable (in stdout) comments, and have no other effect
#	@ change the expect timeout value
#	! Embedded Expect commands
# For more info see: expect-lite.html

#*~fail.inc
#
#	
#	
#
#
;;;

Test 651 Stress vm reboot (heartbeat failure, nova reboots VM)

Based on:
1.Start with at 1 VM running
2.Ensure VM is pingable
3.Ensure you can ssh into the VM from the NAT box.
4.Ensure you can connect to the VM console via the GUI.



Assumptions:
	Lab is setup with lab_setup.sh with Tenants
	Flavors small & medium.dpdk are already provisioned
	

;;;

Steps:
1)  Connect to controller, in prep for connecting to compute
2)  Connect to controller
3)  Become admin
4)  Show version
5)  Check for tenant credentials
6)  Display configuration
7)  Look at neutron config
8)  Set up sudo root access (to make it easier later in the interact session)
9)  Show images in glance
10)  Create big flavor with heartbeat enabled
11)  Get tenant uuids
12)  Look at quotas for $tenant
13)  Increase quotas for test
14)  Get volumes
15)  Check for running VMs
16)  Switch to tenant mode
17)  Boot VMs
18)  Wait for VM to boot up
19)  Check VMs are not in ERROR state
20)  Get VM mananagement IP
21)  Stress loop count: $count
22)  Stop hearbeat on VM
23)  Set up sudo root access (to make it easier later in the interact session)
24)  Ping VM
25)  Connect to VM
26)  Inside VM, check filesystem and ping
27)  Become admin
28)  Wait for VM to boot up
29)  Check VMs are not in ERROR state
30)  Stress done
31)  Cleanup
32)  Switch to tenant mode
33)  Become Admin to delete flavor
34)  Reset quotas for $tenant


*NOFAIL
*EXP_INFO

$IP=10.10.10.2

# support custom ports
?if $PORT != $blank ? $ssh_opts= -p $PORT 

$user=wrsroot
$pass=li69nux

$tenant_credentials=/home/wrsroot/openrc.tenant1
$tenant=$tenant_credentials
# trim to just last part
=$tenant;.*[.](\w+);\1;

# expand quotas for scaling test
$quota_instances=30
$quota_vcpus=60
$quota_port=60

# flavors used by VM1 and VM2
$flavor2=small
$flavor1=medium.dpdk
$flavor1=big

# second flavor and number of vcpus
$flavor3=big
$flavor3_vcpu=1

$best_effort=true
$best_effort=false

$max_vms=2

# which vm to use to test
$test_vm=1


# number of times to stress
$max_stress=15
$max_stress=2

# VM names
$guest1=VM1
$guest2=VM2

# image name
$image_name=cgcs-guest
$image_name=wrl5


# wait for "other" compute to be up before proceeding in stress loop
$wait_for_second_compute=yes
$max=50
# minimum number of computes available when evacuating
$min_controllers=2

#vm file system test
$vm_fs_test=while (true) do date; dd if=/dev/urandom of=output.txt bs=1k count=1 conv=fsync || break ; echo ; sleep 1; done 2>&1 | tee trace.txt



@3
*FORK compute1
; === connect to controller, in prep for connecting to compute

>ssh -X $ssh_opts -o UserKnownHostsFIle=/dev/null -o StrictHostKeyChecking=no $user@$IP
-<WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED
<ssword:|WARNING:
>>$pass

>export TMOUT=0
>





*FORK default

; === connect to controller


>ssh -X $ssh_opts -o UserKnownHostsFIle=/dev/null -o StrictHostKeyChecking=no $user@$IP
-<WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED
<ssword:|WARNING:
>>$pass
<SYSTEM:|WARNING:
+$system_type=(vbox|yow-cgcs-ironpass-\d+|yow-cgcs-hp380-\d+)

?if $system_type == __NO_STRING_CAPTURED__ ? $system_type=vbox

>export TMOUT=0

; === become admin

>source /etc/nova/openrc 



; === show version

>system show
>cat /etc/build.info


; === check for tenant credentials
>stat -t $tenant_credentials
+$file_stat=\n.*($tenant_credentials|No such file)

?if $file_stat != $tenant_credentials? [
		;red Tenant Credentials file:$tenant_credentials missing, skipping
		*TERM 5
]


---------------- start test ---------------------

>system host-list


; === display configuration

; === look at neutron config
# prep for getting to VM
>neutron net-list
+$internal_net_uuid=([0-9a-f-]{36}) \| internal0
+$tenant1_net_uuid=([0-9a-f-]{36}) \| tenant1-net0
+$tenant1_mgmt_net_uuid=([0-9a-f-]{36}) \| tenant1-mgmt-net

>neutron dhcp-agent-list-hosting-net $tenant1_mgmt_net_uuid
+$vm_netns_host=(compute-\d+)
>

*FORK compute1
; --- set up for backdoor to log into VM
@10
>ssh -o UserKnownHostsFIle=/dev/null -o StrictHostKeyChecking=no $vm_netns_host
<ssword:|WARNING:
>>$pass
; === set up sudo root access (to make it easier later in the interact session)
>echo "$pass" | sudo -S id
<root
>sudo su
>

*FORK default

>neutron subnet-list
>neutron router-list


; === show images in glance
>glance image-list
<[0-9a-f-]{36} \|
+$glance_image_name=((\w+|-)+)



; === create big flavor with heartbeat enabled
@5
>nova flavor-create $flavor3 5f0d748b-1c8b-4a70-8643-4d57e25ac137 512 1 $flavor3_vcpu
#>nova flavor-key 5f0d748b-1c8b-4a70-8643-4d57e25ac137 unset guest:heartbeat=False
>nova flavor-key 5f0d748b-1c8b-4a70-8643-4d57e25ac137 set guest:heartbeat=True
>nova flavor-list --extra-spec


>nova flavor-list
<VCPU_Model
+$flavor1_uuid=([0-9a-f-]{36}|\d{3})\s* \| $flavor1 
+$flavor2_uuid=([0-9a-f-]{36}|\d{3})\s* \| $flavor2 

; === get tenant uuids
>keystone tenant-list
<name
+$tenant_uuid=([0-9a-f-]{32}|\d{3})\s* \| $tenant 

; === Look at quotas for $tenant
>nova quota-show --tenant $tenant_uuid
<instances
+$tenant_quota_instances=(\d+)
<cores
+$tenant_quota_vcpus=(\d+)

>neutron quota-show --tenant-id $tenant_uuid
<port
+$tenant_quota_port=(\d+)

?if $system_type != vbox ? [
	; === increase quotas for test
	>nova quota-update --instances $quota_instances $tenant_uuid
	>nova quota-update --cores $quota_vcpus $tenant_uuid
	# must use tenant uuid when updating neutron quotas
	>neutron quota-update --port $quota_port --tenant-id $tenant_uuid
]


; === get volumes
>nova volume-list
+$volume_uuid=([0-9a-f-]{36}) \|


$i=1
; === check for running VMs
# use existing VM rather than starting one.
>nova list --all-tenants | grep tenant1
+$vm_uuid_$i=([0-9a-f-]{36}) \| 

#; == get VM names
#$i=1
#>nova list --all-tenants | grep tenant1
#<$vm_uuid_$i
#+$guest1_$i=\| (\S+)

; === switch to tenant mode
>source $tenant_credentials




?if $vm_uuid_$i == __NO_STRING_CAPTURED__ ?[
	; === boot VMs
	@10
	$i=1
	[ $i <= $max_vms	
		# image boot
		>nova boot --key_name=keypair-tenant1 --flavor=$flavor1_uuid --nic net-id=$tenant1_mgmt_net_uuid,vif-model=virtio --nic net-id=$tenant1_net_uuid,vif-model=virtio --image=$glance_image_name  $guest1-$i
		# cinder boot
		#>nova boot --key_name=keypair-tenant1 --flavor=$flavor1_uuid --nic net-id=$tenant1_mgmt_net_uuid,vif-model=virtio --nic net-id=$tenant1_net_uuid,vif-model=virtio --block_device_mapping vda=$cinder_volume:::0  $guest1-$i
		!sleep 3
		>nova list
		+$vm_uuid_$i=([0-9a-f-]{36}) \| $guest1-$i

		#+$vm_name=$guest1_$i
		$guest1_$i=$guest1-$i
		+$i
	]
	$use_existing_vm=no
]::[
	$use_existing_vm=yes
	>nova list
	+$guest1_$i=$vm_uuid_$i \| ([a-zA-Z0-9_-]+)

]
# only 1 VM for now
-$i
$max_vms=$i

; === wait for VM to boot up
@20
$i=0
$max=50
$vm_state=none
[ $vm_state != ACTIVE
	>nova list
	<$guest1_$max_vms
	+$vm_state=(BUILD|ACTIVE|ERROR)

	!sleep 5
	+$i
	?if $i > $max? %BREAK_VM_BOOT
	
	?if $vm_state == ERROR? %BREAK_VM_BOOT
]
%BREAK_VM_BOOT
@5
; === check VMs are not in ERROR state
>nova list
<Networks
-<ERROR

; === get VM mananagement IP
$i=1
[ $i <= $max_vms
	>nova list --all-tenants
	<$guest1_$i
	+$vm_ip$i=tenant1-mgmt-net=([0-9.]{7,15})
	+$i
]




------- start stress loop
*FORK default 
$count=0
[ $count < $max_stress
	; === stress loop count: $count
	

	; === stop hearbeat on VM
	*FORK compute1
	>>
	$k=1
	; === set up sudo root access (to make it easier later in the interact session)
	>echo "$pass" | sudo -S id
	<root
	>sudo su
	>ip netns list
	+$ns=\n(.*$tenant1_mgmt_net_uuid)
	?if $system_type != vbox ? $ping_count=5 :: $ping_count=35
	; === ping VM
	@50
	>ip netns exec $ns ping -c $ping_count $vm_ip$k
	<ttl=64
	>>^C

	>ip netns exec $ns ping -c 2 $vm_ip$k
	+$ping_result=(\d+ received| 0 received)
	@5
	?if $ping_result != 0 received ? [
		; waiting for sshd service...
		#!sleep 5
		; === connect to VM
		*/.*: /
		$i=0
		$response=refused
		[ $response != ssword
			>ip netns exec $ns ssh -o UserKnownHostsFIle=/dev/null -o StrictHostKeyChecking=no root@$vm_ip$k
			+$response=(ssword|refused|Warning)
			!sleep 2
			+$i
			; --- retry $i
			?if $i > $max? [
				;red VM:$vm_ip sshd not responding
				*FAIL
				>exit
				>exit
				>
				# bail early
				?if true == true? %CLEANUP
			]
		]
		#<ssword:|Last login:
		>>root
		; === inside VM, check filesystem and ping
		# clear prompt
		*//
		@5
		>root
		>
		>mount | grep root
		</ type \w+ \(rw
		>ip route
		<default via
		+$vm_default_gw=([0-9.]{7,15})
		@10
		~=3
		>ping -c 5 $vm_default_gw
		~<(4) received
		# wait for heartbeat to start
		!sleep 5
		>ps -ef | grep heartbeat
		>pkill -9 heartbeat
		<Power button pressed
		>>
		>

	
	]

	
	*FORK default
	>>
	; === become admin
	>source /etc/nova/openrc 
	>system  alarm-list 
	<700.00\d
	>
	>source /home/wrsroot/openrc.tenant1

	; === wait for VM to boot up
	@20
	$i=0
	$max=50
	$vm_state=none
	[ $vm_state != ACTIVE
		>nova list
		<$guest1_$test_vm
		+$vm_state=(BUILD|ACTIVE|ERROR|REBOOT)

		!sleep 5
		+$i
		?if $i > $max? %BREAK_VM_BOOT2

		?if $vm_state == ERROR? %BREAK_VM_BOOT2
	]
	%BREAK_VM_BOOT2
	@5
	; === check VMs are not in ERROR state
	>nova list
	<Networks
	-<ERROR

	
	+$count
]
# end of max_stress



; === stress done

*INTERACT


%CLEANUP
*FORK default
; === cleanup 
@10
; === switch to tenant mode
>source $tenant_credentials

?if $use_existing_vm==no ? [
	$i=1
	[ $i <= $max_vms
		>nova delete $vm_uuid_$i
		+$i
	]
]

>
!sleep 1
>nova list

; === Become Admin to delete flavor
>source /etc/nova/openrc 
>nova flavor-delete $flavor3

?if $system_type != vbox ? [
	; === reset quotas for $tenant
	>nova quota-update --instances $tenant_quota_instances $tenant_uuid
	>nova quota-update --cores $tenant_quota_vcpus $tenant_uuid
	>neutron quota-update --port $tenant_quota_port --tenant-id $tenant_uuid
]
>


