#!/usr/bin/env expect-lite

# How to use this expect-lite file, Lines that begin with:
#	'>' send to remote host, implies "wait for prompt"
#	'<' _MUST_ be received from the remote host, or this config script will fail
#	# are comment lines, and have no effect
#	; are printable (in stdout) comments, and have no other effect
#	@ change the expect timeout value
#	! Embedded Expect commands
# For more info see: expect-lite.html

#*~fail.inc
#
#	
#	
#
#
;;;

Test 561 Stress evacuation

Based on:
        Cinder Volumes are setup (all VMs boot from a cinder volume)
        Start by identifying a compute node which is running VMs
        1. Trigger a 'VM evacuation' by issuing reboot -f to a compute node
        2. All VMs successfully relaunch
        3. Observe all VMs relaunch on remaining compute nodes in the system
        4. Ping/ICM test successfully continues after relaunch
        5. Note the outage time
        6. All VMs remain in Active/Running state
        7. There are no stale NFS on the VMs (use mount cmd to verify
            that the rootfs is r/w)
        8. There is no impact to other VMs
        9. Repeat the steps 1-8 10 times

Script can also be used as a scaling test:
	./nova_migrate_live_scale.elt IP=yow-cgcs-hp380-1 

Assumptions:
	Lab is setup with lab_setup.sh with Tenants
	Flavors small & medium.dpdk are already provisioned
	

;;;

Steps:
1)  Connect to controller, in prep for connecting to compute
2)  Connect to controller
3)  Become admin
4)  Show version
5)  Check for tenant credentials
6)  Display configuration
7)  Look at neutron config
8)  Show volumes in cinder
9)  Create big flavor
10)  Get tenant uuids
11)  Look at quotas for $tenant
12)  Increase quotas for test
13)  Switch to tenant mode
14)  Get volumes
15)  Check for running VMs
16)  Boot VMs
17)  Wait for VM to boot up
18)  Check VMs are not in ERROR state
19)  Get VM mananagement IP
20)  Stress loop count: $count
21)  Become admin
22)  Wait for second compute to be available
23)  Evacuate VMs
24)  Set up sudo root access (to make it easier later in the interact session)
25)  Wait for compute to alarm
26)  Refresh name space net host
27)  Switch to tenant mode
28)  Wait for VM to finish migrating
29)  Check VMs are not in ERROR state
30)  Become admin
31)  Set up sudo root access (to make it easier later in the interact session)
32)  Ping VM
33)  Connect to VM
34)  Inside VM, check filesystem and ping
35)  Stress done
36)  Cleanup
37)  Switch to tenant mode
38)  Become Admin to delete flavor
39)  Reset quotas for $tenant


*NOFAIL
*EXP_INFO

$IP=10.10.10.2

# support custom ports
?if $PORT != $blank ? $ssh_opts= -p $PORT 

$user=wrsroot
$pass=li69nux

$tenant_credentials=/home/wrsroot/openrc.tenant1
$tenant=$tenant_credentials
# trim to just last part
=$tenant;.*[.](\w+);\1;

# expand quotas for scaling test
$quota_instances=30
$quota_vcpus=60
$quota_port=60

# flavors used by VM1 and VM2
$flavor2=small
$flavor1=medium.dpdk
$flavor1=big

# second flavor and number of vcpus
$flavor3=big
$flavor3_vcpu=1

$best_effort=true
$best_effort=false

$max_vms=1

# number of times to stress
$max_stress=10

# VM names
$guest1=VM1
$guest2=VM2

# image name
$image_name=cgcs-guest
$image_name=wrl5


# wait for "other" compute to be up before proceeding in stress loop
$wait_for_second_compute=yes
$max=50
# minimum number of computes available when evacuating
$min_computes=2

@3
*FORK compute
; === connect to controller, in prep for connecting to compute

>ssh -X $ssh_opts -o UserKnownHostsFIle=/dev/null -o StrictHostKeyChecking=no $user@$IP
-<WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED
<ssword:|WARNING:
>>$pass
<SYSTEM:
+$system_type=(vbox|yow-cgcs-ironpass-\d+|yow-cgcs-hp380-\d+)

>export TMOUT=0
>


*FORK default

; === connect to controller


>ssh -X $ssh_opts -o UserKnownHostsFIle=/dev/null -o StrictHostKeyChecking=no $user@$IP
-<WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED
<ssword:|WARNING:
>>$pass
<SYSTEM:
+$system_type=(vbox|yow-cgcs-ironpass-\d+|yow-cgcs-hp380-\d+)

>export TMOUT=0

; === become admin

>source /etc/nova/openrc 

; === show version

>system show
>cat /etc/build.info


; === check for tenant credentials
>stat -t $tenant_credentials
+$file_stat=\n.*($tenant_credentials|No such file)

?if $file_stat != $tenant_credentials? [
		;red Tenant Credentials file:$tenant_credentials missing, skipping
		*TERM 5
]


---------------- start test ---------------------

>system host-list


; === display configuration

; === look at neutron config
# prep for getting to VM
>neutron net-list
+$internal_net_uuid=([0-9a-f-]{36}) \| internal0
+$tenant1_net_uuid=([0-9a-f-]{36}) \| tenant1-net0
+$tenant1_mgmt_net_uuid=([0-9a-f-]{36}) \| tenant1-mgmt-net

>neutron dhcp-agent-list-hosting-net $tenant1_mgmt_net_uuid
+$vm_netns_host=(compute-\d+)

>neutron subnet-list
>neutron router-list


; === show volumes in cinder
>cinder list --all-tenants 
>cinder list --all-tenants  |grep $tenant
+$cinder_volume=([0-9a-f-]{36})

?if $cinder_volume == __NO_STRING_CAPTURED__? [
	;red No cinder volume found
	*FAIL
	?if true == true? %CLEANUP
]


; === create big flavor 

>nova flavor-create $flavor3 5f0d748b-1c8b-4a70-8643-4d57e25ac137 512 1 $flavor3_vcpu


>nova flavor-list
<VCPU_Model
+$flavor1_uuid=([0-9a-f-]{36}|\d{3})\s* \| $flavor1 
+$flavor2_uuid=([0-9a-f-]{36}|\d{3})\s* \| $flavor2 

; === get tenant uuids
>keystone tenant-list
<name
+$tenant_uuid=([0-9a-f-]{32}|\d{3})\s* \| $tenant 

; === Look at quotas for $tenant
>nova quota-show --tenant $tenant_uuid
<instances
+$tenant_quota_instances=(\d+)
<cores
+$tenant_quota_vcpus=(\d+)

>neutron quota-show --tenant-id $tenant_uuid
<port
+$tenant_quota_port=(\d+)

?if $system_type != vbox ? [
	; === increase quotas for test
	>nova quota-update --instances $quota_instances $tenant_uuid
	>nova quota-update --cores $quota_vcpus $tenant_uuid
	# must use tenant uuid when updating neutron quotas
	>neutron quota-update --port $quota_port --tenant-id $tenant_uuid
]



; === switch to tenant mode
>source $tenant_credentials

; === get volumes
>nova volume-list
+$volume_uuid=([0-9a-f-]{36}) \|


$i=1
; === check for running VMs
# use existing VM rather than starting one.
>nova list
+$vm_uuid_$i=([0-9a-f-]{36}) \| 


?if $vm_uuid_$i == __NO_STRING_CAPTURED__ ?[
	; === boot VMs
	@10
	#>nova boot --key_name=keypair-tenant1 --flavor=$flavor1_uuid --nic net-id=$tenant1_mgmt_net_uuid,vif-model=virtio --nic net-id=$tenant1_net_uuid,vif-model=virtio --image=$glance_image_name  $guest1-$i
	>nova boot --key_name=keypair-tenant1 --flavor=$flavor1_uuid --nic net-id=$tenant1_mgmt_net_uuid,vif-model=virtio --nic net-id=$tenant1_net_uuid,vif-model=virtio --block_device_mapping vda=$cinder_volume:::0  $guest1-$i
	!sleep 3
	>nova list
	+$vm_uuid_$i=([0-9a-f-]{36}) \| $guest1-$i
	
	#+$vm_name=$guest1_$i
	$guest1_$i=$guest1-$i
	$use_existing_vm=no
]::[
	$use_existing_vm=yes
	>nova list
	+$guest1_$i=$vm_uuid_$i \| ([a-zA-Z0-9_-]+)

]
# only 1 VM for now
$max_vms=$i

; === wait for VM to boot up
@20
$i=0
$max=50
$vm_state=none
[ $vm_state != ACTIVE
	>nova list
	<$guest1_$max_vms
	+$vm_state=(BUILD|ACTIVE|ERROR)

	!sleep 5
	+$i
	?if $i > $max? %BREAK_VM_BOOT
	
	?if $vm_state == ERROR? %BREAK_VM_BOOT
]
%BREAK_VM_BOOT
@5
; === check VMs are not in ERROR state
>nova list
<Networks
-<ERROR

; === get VM mananagement IP
>nova list --all-tenants
<$guest1_$max_vms
+$vm_ip=tenant1-mgmt-net=([0-9.]{7,15})

------- start stress loop

$count=0
[ $count < $max_stress
	; === stress loop count: $count
	
	; === become admin
	>source /etc/nova/openrc 

	>nova show $vm_uuid_$max_vms
	<OS-EXT-SRV-ATTR:host
	+$vm_compute_host1=(compute-\d+)


	?if $wait_for_second_compute == yes? [
		; === wait for second compute to be available
		>system host-list | grep compute | grep available
		>system host-list | grep compute | grep available | wc -l
		$i=0
		+$num_of_computes=\n(\d)
		[ $num_of_computes < $min_computes
			>system host-list | grep compute | grep available | wc -l
			+$num_of_computes=\n(\d)
			!sleep 5
			+$i
			?if $i > $max ? %STOP_WAIT
		]
		%STOP_WAIT
		>system host-list | grep compute | grep available
	]
	; === Evacuate VMs
	*FORK compute
	@30
	>ssh -o StrictHostKeyChecking=no $vm_compute_host1
	<ssword:|WARNING:
	>>$pass
	; === set up sudo root access (to make it easier later in the interact session)
	@5
	>echo "$pass" | sudo -S id
	<root
	>sudo reboot -f && exit
	!sleep 2
	>>
	>>
	
	*FORK default
	>
	; === wait for compute to alarm
	$compute_alarm=none
	[ $compute_alarm != 200.005 
		>system alarm-list
		+$compute_alarm=(200.005).*host=$vm_compute_host1
		!sleep 2
	]
	>
	!sleep 5
	; === refresh name space net host
	>neutron dhcp-agent-list-hosting-net $tenant1_mgmt_net_uuid
	+$vm_netns_host=(compute-\d+)
	
	@5
	; === switch to tenant mode
	>source $tenant_credentials
	; === wait for VM to finish migrating

	$i=0
	$max=50
	$vm_state=none
	[ $vm_state != ACTIVE
		>nova list
		<$guest1_$max_vms
		+$vm_state=(BUILD|ACTIVE|ERROR|MIGRATING)

		!sleep 5
		+$i
		?if $i > $max? %BREAK_VM_MIGRATE

		#?if $vm_state == ERROR? %BREAK_VM_MIGRATE
	]
	%BREAK_VM_MIGRATE


	; === check VMs are not in ERROR state
	>nova list
	<Networks
	-<ERROR

	; === become admin
	>source /etc/nova/openrc 

	>nova show $vm_uuid_$max_vms
	<OS-EXT-SRV-ATTR:host
	+$vm_compute_host2=(compute-\d+)

	?if $vm_compute_host2 == $vm_compute_host1 ? [
		;red VM:$guest1_$max_vms did not Migrate
		*FAIL
		#*INTERACT
		# bail early
		?if true == true? %CLEANUP
	]::[
		; --- backdoor to log into VM
		@10
		>ssh -o StrictHostKeyChecking=no  -o UserKnownHostsFIle=/dev/null  $vm_netns_host
		<ssword:|WARNING:
		>>$pass
		; === set up sudo root access (to make it easier later in the interact session)
		>echo "$pass" | sudo -S id
		<root
		>sudo su
		>ip netns list
		+$ns=\n(.*$tenant1_mgmt_net_uuid)
		?if $system_type != vbox ? $ping_count=10 :: $ping_count=40
		; === ping VM
		@50
		>ip netns exec $ns ping -c $ping_count $vm_ip
		+$ping_result=(\d+ received| 0 received)
		@5
		?if $ping_result != 0 received ? [
			; waiting for sshd service...
			#!sleep 5
			; === connect to VM
			*/.*: /
			$i=0
			$response=refused
			[ $response != ssword
				>ip netns exec $ns ssh -o UserKnownHostsFIle=/dev/null -o StrictHostKeyChecking=no root@$vm_ip
				+$response=(ssword|refused|Warning)
				!sleep 2
				+$i
				; --- retry $i
				?if $i > $max? [
					;red VM:$vm_ip sshd not responding
					*FAIL
					>exit
					>exit
					>
					# bail early
					?if true == true? %CLEANUP
				]
			]
			#<ssword:|Last login:
			>>root
			; === inside VM, check filesystem and ping
			@5
			>root
			>
			>mount | grep root
			</ type \w+ \(rw
			>ip route
			<default via
			+$vm_default_gw=([0-9.]{7,15})
			>ping -c 2 $vm_default_gw
			<(2|1) received
			>exit
			# clear custom prompt
			*//
		]::[
			;red VM:$vm_ip not responding
			*FAIL
			>exit
			>exit
			>
			# bail early
			?if true == true? %CLEANUP
			
		]
		# exit from compute
		>exit
		>exit
		# back on controller
		>hostname
		<\ncontroller-\d
		>
		### Check Ixia Data (if running)
	]
	+$count
]
# end of max_stress



; === stress done

*INTERACT

%CLEANUP
; === cleanup 
@10
; === switch to tenant mode
>source $tenant_credentials

?if $use_existing_vm==no ? [
	$i=1
	[ $i <= $max_vms
		>nova delete $vm_uuid_$i
		+$i
	]
]

>
!sleep 1
>nova list

; === Become Admin to delete flavor
>source /etc/nova/openrc 
>nova flavor-delete $flavor3

?if $system_type != vbox ? [
	; === reset quotas for $tenant
	>nova quota-update --instances $tenant_quota_instances $tenant_uuid
	>nova quota-update --cores $tenant_quota_vcpus $tenant_uuid
	>neutron quota-update --port $tenant_quota_port --tenant-id $tenant_uuid
]
>


